{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e1857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import scipy\n",
    "from os.path import basename\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from pytorch_toolbelt.losses import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1283ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation.batch_loader import * # these are scripts created by us\n",
    "from unet.Network import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42479caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and create train and validation laoder\n",
    "\n",
    "data_path = r\"/zhome/20/8/175218/data/clean_data/*.*\"\n",
    "train_one_hot, train_image, train_image_standard, train_image_standard_hot = image_standard_format(path)\n",
    "test_one_hot, test_image, test_image_standard, test_image_standard_hot = test_images(train_one_hot, # one hot encoded image\n",
    "                                                                                     train_image, # real image\n",
    "                                                                                     train_image_standard, # four dimension array with 3 channels for RGB in one channel \n",
    "                                                                                     train_image_standard_hot) # four dimension array for batch creation and in image are four classes \n",
    "trainloader, validloader = batch(train_image_standard,\n",
    "                                 train_image_standard_hot) # create train and validation loader with batch size 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose network \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_for_training = \"deeplab\"\n",
    "if model_for_training != \"deeplab\":\n",
    "    Net = U_Net_Model() # you can find it in the script Network where we wrote the UNet on ourself to be able to understand it but also to add dropout at various stages\n",
    "else:\n",
    "    Net = torchvision.models.segmentation.deeplabv3_resnet101(num_classes = 9) # loading deeplab model and configure 9 classes for output\n",
    "    Net.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e06b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assign network to cuda if available\n",
    "if torch.cuda.is_available():\n",
    "    Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameters\n",
    "LEARNING_RATE = 0.00004\n",
    "wDecay = 0.000001\n",
    "epochs = 100\n",
    "min_valid_loss = np.inf\n",
    "class_weights = torch.tensor([0.2, 1, 1, 1, 1, 3, 3, 3, 3],dtype=torch.float).cuda() # here you can change the weights for the corresponding class. For instance, the first one is the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(Net.parameters(), lr=LEARNING_RATE, weight_decay=wDecay)\n",
    "criterion1 = DiceLoss( mode = 'multilabel') ## for our final result we used a combined loss with dice and crossEntropy. Multilabel considers the fact that we have muliple classes in our result\n",
    "criterion2 = nn.CrossEntropyLoss(weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## m\n",
    "def accuracy(ys, ts):\n",
    "    predictions = torch.max(ys, 1)[1]\n",
    "    correct_prediction = torch.eq(predictions, ts)\n",
    "    return torch.mean(correct_prediction.float())\n",
    "validation_losses = []\n",
    "validation_accuracies = []\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training and validation \n",
    "# the model is saved when the lowest overall loss in validation is achieved\n",
    "for e in range(epochs):\n",
    "    print(e)\n",
    "    train_loss = 0.0\n",
    "    n_totalT = 0\n",
    "    numT = 0\n",
    "    train_accuracies_batches = []\n",
    "    valid_accuracies_batches = []\n",
    "    Net.train()    \n",
    "    for data, target in trainloader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = Net(data)['out']\n",
    "        loss = criterion1(pred,target) + criterion2(pred,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        numT += len(target)\n",
    "        train_loss += loss.item()*len(target)\n",
    "        n_totalT += 1\n",
    "        step =+ 1\n",
    "        predictions = pred.max(1)[1]\n",
    "        train_accuracies_batches.append(accuracy(target, predictions))\n",
    "    b = sum(train_accuracies_batches)/n_totalT\n",
    "    training_accuracies.append(b.cpu().numpy()) # for plot\n",
    "    training_losses.append(train_loss / numT)\n",
    "    valid_loss = 0.0\n",
    "    Net.eval()     \n",
    "    numV = 0\n",
    "    n_totalV = 0\n",
    "    for data, labels in validloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        pred = Net(data)['out']\n",
    "        loss = criterion1(pred,labels) + criterion2(pred,labels)\n",
    "        valid_loss += loss.item() * len(labels)\n",
    "        numV += len(labels)\n",
    "        \n",
    "        n_totalV += 1\n",
    "        predictions = pred.max(1)[1]\n",
    "        valid_accuracies_batches.append(accuracy(labels, predictions))\n",
    "    a = sum(valid_accuracies_batches) / n_totalV\n",
    "    validation_accuracies.append(a.cpu().numpy()) # for plot\n",
    "    print(a.cpu().numpy())\n",
    "    validation_losses.append(valid_loss / numV)\n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / numT} \\t\\t Validation Loss: {valid_loss / numV}')\n",
    "    print(f'Epoch {e+1} \\t\\t Train Accuracy: {sum(train_accuracies_batches)/n_totalT} \\t\\t Validation Accuracy: {sum(valid_accuracies_batches) / n_totalV}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "       # torch.savexite(Net.state_dict(), 'saved_model_dice_deepCE_smol_col_W.pth')\n",
    "        # Log i figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f74e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_range = np.arange(0, epochs, 1)\n",
    "validation_losses = np.array(validation_losses)\n",
    "np.savetxt(\"validation_losses\", validation_losses)\n",
    "validation_accuracies = np.array(validation_accuracies)\n",
    "np.savetxt(\"validation_accuracies\", validation_accuracies)\n",
    "training_accuracies = np.array(training_accuracies)\n",
    "np.savetxt(\"training_accuracies\", training_accuracies)\n",
    "training_losses = np.array(training_losses)\n",
    "np.savetxt(\"training_losses\", training_losses)\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_range, training_losses, label='train_loss')\n",
    "plt.plot(epoch_range, validation_losses, label='valid_loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

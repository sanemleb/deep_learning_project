{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FINAL PROJECT - 02456 DEEP LEARNING\n",
        "### SEGMENTATION OF CAR PARTS \n",
        "### COLLABORATION WITH DELOITTE CONSULTING\n",
        "\n",
        "#### Authors\n",
        ">*Sanem Leblebici - s222448*\n",
        "\n",
        ">*Michal Lehwark - s222999*\n",
        "\n",
        ">*Ari Menachem - s163956*\n",
        "\n",
        ">*Elli Georgiou - s223408*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUxu-ANAg8Zg",
        "outputId": "f015ad66-1c10-4648-fd6d-43a267e3c3aa"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from modules.model import UNET, UNET_RESNET\n",
        "from modules.unetPP import UNetPP \n",
        "from modules.settings import DATA_PATH, NUM_EPOCHS,BATCH_SIZE,SPLIT_RATIO, LEARNING_RATE, device\n",
        "from modules.utils import get_data_loaders, pixel_accuracy, save_metric_to_file, mean_pixel_accuracy, save_dice_loss_to_file\n",
        "from modules.resizeImages import resize_with_pad\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "from typing import Tuple\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms as T\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIwpdC5dW40J"
      },
      "source": [
        "### Load the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIvdhlxuS5Z6",
        "outputId": "3101603f-66e8-4cb8-e911-16bd5cd8887a"
      },
      "outputs": [],
      "source": [
        "mdl = UNET()\n",
        "# mdl = UNET_RESNET(3)\n",
        "# mdl = UNetPP()\n",
        "\n",
        "## Can uncomment the next line if your device has gpu\n",
        "# mdl.load_state_dict(torch.load('./models/unet_nov18.pth'))\n",
        "\n",
        "model_name = \"unet_dec2_3.pth\"\n",
        "model_type = str(type(mdl))\n",
        "\n",
        "mdl.load_state_dict(torch.load('./models/old/dec2/'+model_name, map_location=torch.device('cpu')))\n",
        "# mdl.load_state_dict(torch.load('./models/experiment_outputs/output_models_arrays_1_unet/'+model_name, map_location=torch.device('cpu')))\n",
        "print(f\"{model_type} loaded: {model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpckeoQ_6ISF"
      },
      "source": [
        "### TEST LOOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InLjwON36IHk",
        "outputId": "a9d24ecd-eca8-4135-829b-f627d393fc7f"
      },
      "outputs": [],
      "source": [
        "masks_path = './data/carseg_data/test_arrays_mask_corrected'\n",
        "# masks_path = \"./data/carseg_data/FINAL_select_augmented_arrays\"\n",
        "# masks_path = \"./data/carseg_data/unused/arrays_no_bg_augment\"\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "# Create a list to store the model outputs\n",
        "model_outputs = []\n",
        "model_outputs_images = []\n",
        "model_outputs_gt = []\n",
        "model_output_pixelAcc = [] \n",
        "filenames_in_order = []\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "mdl.eval()\n",
        "\n",
        "# Define the transformation to be applied to the input images\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "reverse_transform = transforms.Compose([transforms.ToPILImage()])\n",
        "how_many_images_to_test = 30\n",
        "index = 0\n",
        "\n",
        "for filename in os.listdir(masks_path):\n",
        "  mask_path = os.path.join(masks_path, filename)\n",
        "  mask = np.load(mask_path, allow_pickle=True)\n",
        "  \n",
        "        \n",
        "  img = mask[:, :, :3]\n",
        "  mask_split = mask[:, :, 3]\n",
        "  mask_split = mask_split.astype(int)\n",
        "  one_hot_encoded = np.eye(10, dtype=int)[mask_split.squeeze()]\n",
        "  dice_mask = np.expand_dims(one_hot_encoded.transpose(2,0,1), axis=0)\n",
        "        \n",
        "  img = transform(img)\n",
        "  img_rev = reverse_transform(img)\n",
        "            \n",
        "  mdl.eval()\n",
        " # Make the prediction\n",
        "  with torch.no_grad():\n",
        "    img = img.unsqueeze(0)\n",
        "    filenames_in_order.append(filename)\n",
        "    output = mdl(img)\n",
        "    # sigmoid_output = torch.sigmoid(output)\n",
        "    argmax_output = torch.argmax(output, dim=1)\n",
        "\n",
        "    # Calculate pixel accuracy\n",
        "    accuracy = pixel_accuracy(argmax_output[0], torch.tensor(mask_split))\n",
        "    model_output_pixelAcc.append(accuracy)\n",
        "    \n",
        "  # Store the output in the list\n",
        "  model_outputs.append(argmax_output[0])\n",
        "  model_outputs_images.append(img_rev)\n",
        "  model_outputs_gt.append(torch.tensor(mask_split))\n",
        "\n",
        "  #detect for first 10 images\n",
        "  if index == how_many_images_to_test:\n",
        "    break\n",
        "  index = index + 1\n",
        "\n",
        "# The `model_outputs` list now contains the model's output for each test image\n",
        "# Calculate and print mean pixel accuracy\n",
        "mean_accuracy = mean_pixel_accuracy(model_outputs, model_outputs_gt)\n",
        "\n",
        "\n",
        "# Save scores to a file\n",
        "mean_dice = save_dice_loss_to_file(\"./dice_scores.txt\", model_outputs, model_outputs_gt, filenames_in_order)\n",
        "save_metric_to_file(\"./scores.txt\", model_type, model_name, mean_accuracy, mean_dice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofBpeCgY6ERu"
      },
      "source": [
        "### COLORFUL SEGMENTATION PLOT AND LOSS PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_loss_from_txt(file_path):\n",
        "    # Read data from the text file\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Extract data from each line\n",
        "    indices, train_losses, val_losses = [], [], []\n",
        "    for line in lines[1:]:  # Assuming the first line contains column headers\n",
        "        index, train_loss, val_loss = map(float, line.strip().split())\n",
        "        indices.append(index)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Plot the training and validation losses\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot Training Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(indices, train_losses, label='Train Loss', marker='o', linestyle='-')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Validation Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(indices, val_losses, label='Validation Loss', marker='o', linestyle='-')\n",
        "    plt.title('Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_from_txt('./models/loss_data_nov26_1.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "y0P9NTrz6D-T",
        "outputId": "92a98f82-fbf2-4bfc-9cd8-ed39f3e25d55"
      },
      "outputs": [],
      "source": [
        "# Define color mapping for each class\n",
        "color_mapping = {\n",
        "        0: (0,0,0),\n",
        "        1: (250, 149, 10),\n",
        "        2: (19, 98, 19),\n",
        "        3: (249, 249, 10),\n",
        "        4: (10, 248, 250),\n",
        "        5: (149, 7, 149),\n",
        "        6: (5, 249, 9),\n",
        "        7: (20, 19, 249),\n",
        "        8: (249, 9, 250),\n",
        "        9: (150, 150, 150),\n",
        "    }\n",
        "\n",
        "def colorize_segmentation_mask(segmentation_tensor_or_mask, mask = False):\n",
        "    # Convert the PyTorch tensor to a NumPy array\n",
        "    if mask == False:\n",
        "        segmentation_array = segmentation_tensor_or_mask.squeeze(0).cpu().numpy()\n",
        "        \n",
        "    else:\n",
        "        segmentation_array = segmentation_tensor_or_mask\n",
        "\n",
        "    # Create a mapping from actual class values to color values\n",
        "    class_to_color = {class_value: color_mapping[class_value] for class_value in np.unique(segmentation_array)}\n",
        "\n",
        "    # Create an RGB image with the colored segmentation mask\n",
        "    colored_mask = np.zeros((256, 256, 3), dtype=np.uint8)\n",
        "    for class_value, color in class_to_color.items():\n",
        "        colored_mask[segmentation_array == class_value] = color\n",
        "\n",
        "    return colored_mask\n",
        "\n",
        "for image_index_to_display in range(10):\n",
        "    print(filenames_in_order[image_index_to_display])\n",
        "    segmentation_tensor = model_outputs[image_index_to_display]\n",
        "    mask_tensor = model_outputs_gt[image_index_to_display]\n",
        "\n",
        "    pixel_acc_val = model_output_pixelAcc[image_index_to_display]\n",
        "    image_tensor = model_outputs_images[image_index_to_display]\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(colorize_segmentation_mask(mask_tensor, True))\n",
        "    plt.title('Ground Truth Mask')\n",
        "    \n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(image_tensor)\n",
        "    plt.title('Real Image')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(colorize_segmentation_mask(segmentation_tensor))\n",
        "    plt.title(f\"Pred Mask, pxAcc: {pixel_acc_val:.5f}\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TESTING THE PREPROCESSING OF THE MASK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "color_mapping = {\n",
        "        0: (0,0,0),\n",
        "        1: (250, 149, 10),\n",
        "        2: (19, 98, 19),\n",
        "        3: (249, 249, 10),\n",
        "        4: (10, 248, 250),\n",
        "        5: (149, 7, 149),\n",
        "        6: (5, 249, 9),\n",
        "        7: (20, 19, 249),\n",
        "        8: (249, 9, 250),\n",
        "        9: (150, 150, 150),\n",
        "    }\n",
        "\n",
        "\n",
        "#### WHAT WE DO IN DATASET ######\n",
        "img_path = './data/carseg_data/images/photo/no_segmentation/0035.jpg'\n",
        "mask_path = './data/carseg_data/arrays/photo_0035.npy'\n",
        "\n",
        "\n",
        "mask = np.load(mask_path).astype(np.double)\n",
        "im = mask[:, :, :3]\n",
        "mask_split = mask[:, :, 3]\n",
        "mask_split = mask_split//10\n",
        "mask_split = mask_split.astype(int)\n",
        "        \n",
        "        \n",
        "transform = T.Compose([T.ToTensor()])\n",
        "img = transform(im)\n",
        "        \n",
        "one_hot_encoded = np.eye(10, dtype=int)[mask_split.squeeze()]\n",
        "ms = torch.from_numpy(one_hot_encoded)\n",
        "        \n",
        "img = img.to(torch.float32)\n",
        "reshaped_mask_tensor = ms.permute(2, 0, 1)\n",
        "reshaped_mask_tensor = reshaped_mask_tensor.to(torch.float32)\n",
        "\n",
        "\n",
        "#### NOW YOU CAN COMPRESS IT BACK IN THIS WAY SHOWING 10 UNIQUE CLASSES: SO IT WORKS CORRECTLY####\n",
        "print(\"output shape \", reshaped_mask_tensor.shape)\n",
        "print(\"output unique \", torch.unique(reshaped_mask_tensor))\n",
        "argmax_output = torch.argmax(reshaped_mask_tensor, dim=0).long()\n",
        "print(\"argmax shape \", argmax_output.shape)\n",
        "print(\"argmax unique \", torch.unique(argmax_output))\n",
        "#### NOW YOU CAN COMPRESS IT BACK IN THIS WAY SHOWING 10 UNIQUE CLASSES: SO IT WORKS CORRECTLY####\n",
        "\n",
        "\n",
        "\n",
        "##### PLOT THE MASK THAT IS FED INTO THE MODEL ####\n",
        "# Plotting\n",
        "num_classes = 10\n",
        "num_rows = (num_classes + 4) // 5  # Ensure at least 1 row, with max 5 columns\n",
        "fig, axes = plt.subplots(3, 5, figsize=(20, num_rows * 4))\n",
        "\n",
        "# Plot original mask\n",
        "axes[0, 0].imshow(mask, cmap='viridis', vmin=0, vmax=9)\n",
        "axes[0, 0].set_title('Original Mask')\n",
        "\n",
        "im = im.astype(np.uint8)\n",
        "axes[2, 0].imshow(im)\n",
        "axes[2, 0].set_title('image')\n",
        "\n",
        "# Plot one-hot encoded tensors for each class\n",
        "for i in range(num_classes):\n",
        "    row = (i ) // 5\n",
        "    col = (i ) % 5\n",
        "    axes[row, col].imshow(reshaped_mask_tensor[i , :, :], cmap='viridis', vmin=0, vmax=1)\n",
        "    axes[row, col].set_title(f'Class {i }')\n",
        "\n",
        "# Hide empty subplots if necessary\n",
        "for i in range(num_classes, num_rows * 5):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "##### PLOT THE MASK THAT IS FED INTO THE MODEL ####\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CHECKING IF DELOITTE GAVE US GOOD MASKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orange_im_path = \"./data/carseg_data/unused/images/orange_3_doors/with_segmentation\"\n",
        "black_im_path = \"./data/carseg_data/unused/images/black_5_doors/with_segmentation\"\n",
        "photo_im_path = \"./data/carseg_data/unused/images/photo/with_segmentation\"\n",
        "corrected_mask = \"./data/carseg_data/test_arrays_mask_corrected\"\n",
        "\n",
        "mask_name = \"photo_\"\n",
        "\n",
        "color_mapping = {\n",
        "        0: (0,0,0),\n",
        "        1: (250, 149, 10),\n",
        "        2: (19, 98, 19),\n",
        "        3: (249, 249, 10),\n",
        "        4: (10, 248, 250),\n",
        "        5: (149, 7, 149),\n",
        "        6: (5, 249, 9),\n",
        "        7: (20, 19, 249),\n",
        "        8: (249, 9, 250),\n",
        "        9: (0,0,0),\n",
        "    }\n",
        "\n",
        "#### CHECKING THE ORANGE CAR DATA \n",
        "index = 0\n",
        "for im in os.listdir(photo_im_path):\n",
        "\n",
        "    if im.endswith(\".jpg\") or im.endswith(\".png\"):\n",
        "        # Load the image\n",
        "        \n",
        "        image_path = os.path.join(photo_im_path, im)\n",
        "        if \"0004\" not in image_path:\n",
        "            if \"0028\" not in image_path:\n",
        "                continue\n",
        "        \n",
        "        name, ext = im.split('.')\n",
        "        mask_string = mask_name + name + \".npy\"\n",
        "        mask_path = os.path.join('./data/carseg_data/test_arrays', mask_string)\n",
        "        correct_mask_path = os.path.join(corrected_mask, mask_string)\n",
        "        mask = np.load(mask_path)\n",
        "        mask_split = mask[:, :, 3]\n",
        "        mask_split = mask_split//10\n",
        "        mask_split = mask_split.astype(int)\n",
        "        \n",
        "        mask_correct = np.load(correct_mask_path)\n",
        "        mask_split_correct = mask_correct[:, :, 3]\n",
        "        mask_split_correct = mask_split_correct.astype(int)\n",
        "        \n",
        "        img = cv2.imread(image_path)\n",
        "        resized = resize_with_pad(img, (256, 256))\n",
        "        img_rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        colorize_segmentation_mask(mask_split, mask=True)\n",
        "        plt.imshow(img_rgb)\n",
        "        \n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.title('Intended Mask')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        # img_rgb = cv2.cvtColor(model_outputs_images[image_index_to_display], cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(colorize_segmentation_mask(mask_split, mask=True))\n",
        "        plt.title('Numpy Mask')\n",
        "        \n",
        "        plt.subplot(1, 3, 3)\n",
        "        # img_rgb = cv2.cvtColor(model_outputs_images[image_index_to_display], cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(colorize_segmentation_mask(mask_split_correct, mask=True))\n",
        "        plt.title('Corrected Numpy Mask')\n",
        "\n",
        "        if index == 200:\n",
        "            break\n",
        "        index = index + 1\n",
        "        \n",
        "    plt.show() \n",
        "        "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

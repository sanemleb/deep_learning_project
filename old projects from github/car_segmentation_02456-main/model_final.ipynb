{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.24.0\n",
    "%pip install pytorch-toolbelt==0.0.3\n",
    "%pip install torch\n",
    "%pip install matplotlib\n",
    "%pip install scipy\n",
    "%pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import scipy\n",
    "from os.path import basename\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from pytorch_toolbelt.losses import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augmentation.batch_loader import * # these are scripts created by us\n",
    "from unet.Network import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42479caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and create train and validation laoder\n",
    "\n",
    "data_path = r\"/zhome/20/8/175218/data/clean_data/*.*\"\n",
    "train_one_hot, train_image, train_image_standard, train_image_standard_hot = image_standard_format(path)\n",
    "test_one_hot, test_image, test_image_standard, test_image_standard_hot = test_images(train_one_hot, # one hot encoded image\n",
    "                                                                                     train_image, # real image\n",
    "                                                                                     train_image_standard, # four dimension array with 3 channels for RGB in one channel \n",
    "                                                                                     train_image_standard_hot) # four dimension array for batch creation and in image are four classes \n",
    "trainloader, validloader = batch(train_image_standard,\n",
    "                                 train_image_standard_hot) # create train and validation loader with batch size 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose network \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_for_training = \"deeplab\"\n",
    "if model_for_training != \"deeplab\":\n",
    "    Net = U_Net_Model() # you can find it in the script Network where we wrote the UNet on ourself to be able to understand it but also to add dropout at various stages\n",
    "else:\n",
    "    Net = torchvision.models.segmentation.deeplabv3_resnet101(num_classes = 9) # loading deeplab model and configure 9 classes for output\n",
    "    Net.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e06b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## assign network to cuda if available\n",
    "if torch.cuda.is_available():\n",
    "    Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyperparameters\n",
    "LEARNING_RATE = 0.00004\n",
    "wDecay = 0.000001\n",
    "epochs = 100\n",
    "min_valid_loss = np.inf\n",
    "class_weights = torch.tensor([0.2, 1, 1, 1, 1, 3, 3, 3, 3],dtype=torch.float).cuda() # here you can change the weights for the corresponding class. For instance, the first one is the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(Net.parameters(), lr=LEARNING_RATE, weight_decay=wDecay)\n",
    "criterion1 = DiceLoss( mode = 'multilabel') ## for our final result we used a combined loss with dice and crossEntropy. Multilabel considers the fact that we have muliple classes in our result\n",
    "criterion2 = nn.CrossEntropyLoss(weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## m\n",
    "def accuracy(ys, ts):\n",
    "    predictions = torch.max(ys, 1)[1]\n",
    "    correct_prediction = torch.eq(predictions, ts)\n",
    "    return torch.mean(correct_prediction.float())\n",
    "validation_losses = []\n",
    "validation_accuracies = []\n",
    "training_losses = []\n",
    "training_accuracies = []\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training and validation \n",
    "# the model is saved when the lowest overall loss in validation is achieved\n",
    "for e in range(epochs):\n",
    "    print(e)\n",
    "    train_loss = 0.0\n",
    "    n_totalT = 0\n",
    "    numT = 0\n",
    "    train_accuracies_batches = []\n",
    "    valid_accuracies_batches = []\n",
    "    Net.train()    \n",
    "    for data, target in trainloader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = Net(data)['out']\n",
    "        loss = criterion1(pred,target) + criterion2(pred,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        numT += len(target)\n",
    "        train_loss += loss.item()*len(target)\n",
    "        n_totalT += 1\n",
    "        step =+ 1\n",
    "        predictions = pred.max(1)[1]\n",
    "        train_accuracies_batches.append(accuracy(target, predictions))\n",
    "    b = sum(train_accuracies_batches)/n_totalT\n",
    "    training_accuracies.append(b.cpu().numpy()) # for plot\n",
    "    training_losses.append(train_loss / numT)\n",
    "    valid_loss = 0.0\n",
    "    Net.eval()     \n",
    "    numV = 0\n",
    "    n_totalV = 0\n",
    "    for data, labels in validloader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        pred = Net(data)['out']\n",
    "        loss = criterion1(pred,labels) + criterion2(pred,labels)\n",
    "        valid_loss += loss.item() * len(labels)\n",
    "        numV += len(labels)\n",
    "        \n",
    "        n_totalV += 1\n",
    "        predictions = pred.max(1)[1]\n",
    "        valid_accuracies_batches.append(accuracy(labels, predictions))\n",
    "    a = sum(valid_accuracies_batches) / n_totalV\n",
    "    validation_accuracies.append(a.cpu().numpy()) # for plot\n",
    "    print(a.cpu().numpy())\n",
    "    validation_losses.append(valid_loss / numV)\n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / numT} \\t\\t Validation Loss: {valid_loss / numV}')\n",
    "    print(f'Epoch {e+1} \\t\\t Train Accuracy: {sum(train_accuracies_batches)/n_totalT} \\t\\t Validation Accuracy: {sum(valid_accuracies_batches) / n_totalV}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "       # torch.savexite(Net.state_dict(), 'saved_model_dice_deepCE_smol_col_W.pth')\n",
    "        # Log i figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f74e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the accuracy and loss over the different epochs\n",
    "epoch_range = np.arange(0, epochs, 1)\n",
    "validation_losses = np.array(validation_losses)\n",
    "np.savetxt(\"validation_losses\", validation_losses)\n",
    "validation_accuracies = np.array(validation_accuracies)\n",
    "np.savetxt(\"validation_accuracies\", validation_accuracies)\n",
    "training_accuracies = np.array(training_accuracies)\n",
    "np.savetxt(\"training_accuracies\", training_accuracies)\n",
    "training_losses = np.array(training_losses)\n",
    "np.savetxt(\"training_losses\", training_losses)\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_range, training_losses, label='train_loss')\n",
    "plt.plot(epoch_range, validation_losses, label='valid_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7237fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loads the model settings and plots the results based on the test images\n",
    "\n",
    "Net.load_state_dict(model)\n",
    "Net.eval()\n",
    "\n",
    "def nine_to_one(x):\n",
    "    img = np.zeros((256,256))\n",
    "    for i in range(len(x)):\n",
    "        img[:,:] += x[i,:,:]*i\n",
    "    return img\n",
    "\n",
    "\n",
    "select_test = np.arange(30)\n",
    "avg_dice = 0\n",
    "for i,x in enumerate(select_test):\n",
    "    test = Net(X_t[x:x+1])['out']\n",
    "    acc = criterion1(test, Y_t[x:x+1])\n",
    "    acc = acc.item()\n",
    "    #_, test = torch.max(test.data, 1)\n",
    "    test = torch.max(test, 1)[1]\n",
    "    test= test.data.cpu().detach().numpy()\n",
    "    test = np.array(test)[0]\n",
    "    f, axarr = plt.subplots(1,3)\n",
    "    axarr[0].imshow(test)\n",
    "    axarr[0].title.set_text(\"Prediction\")\n",
    "    axarr[0].axis('off')\n",
    "    axarr[1].imshow(test_image_standard_hot_show[x][0])\n",
    "    axarr[1].title.set_text(\"Target\")\n",
    "    axarr[1].axis('off')\n",
    "    axarr[2].imshow(test_image_[x])\n",
    "    axarr[2].title.set_text(\"Original image\")\n",
    "    axarr[2].axis('off')\n",
    "    f.suptitle(\"Dice Score: \" + str(1 - acc)[:4])\n",
    "    f.tight_layout()\n",
    "    f.subplots_adjust(top=1.35)\n",
    "    plt.savefig(path +str(x) + '.png')\n",
    "    plt.show()\n",
    "    avg_dice += acc/30\n",
    "\n",
    "print(avg_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd386116",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this code tests the model and calculates the Dice for the input image stored in drive path\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from skimage.io import imread\n",
    "from skimage import transform as tf\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "import scipy\n",
    "from os.path import basename\n",
    "import os\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, GRU, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from augmentation.image_processing import*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = torch.load(\"/zhome/ed/a/183709/saved_model_dice_deepCE_smol_W_col.pth\")\n",
    "\n",
    "from unet.Network import *\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "drive_path = r\"/zhome/ed/a/183709/data/data/test/*.*\"\n",
    "image_paths = glob.glob(drive_path)\n",
    "\n",
    "test_image_ = [np_transform_bgr(np.load(i)[0:3, :, :) for i in image_paths]\n",
    "test_one_hot_ = [one_hot_image(np.load(i)) for i in image_paths]\n",
    "\n",
    "test_image_standard_hot_show = [np.expand_dims(np.load(i)[3,:,:], axis = 0) for i in image_paths]\n",
    "test_image_standard_hot_ = [one_trans(x) for x in test_image_standard_hot_show]\n",
    "\n",
    "test_image_standard_ = [np.load(i)[0:3,:,:] for i in image_paths] #for non normal\n",
    "test_image_standard = test_image_standard_\n",
    "test_image_standard_hot = test_image_standard_hot_\n",
    "X_t = torch.from_numpy(np.array(test_image_standard, dtype = 'float32'))\n",
    "X_t= X_t.to(device='cuda')\n",
    "Y_t = torch.from_numpy(np.array(test_image_standard_hot, dtype ='float32'))\n",
    "Y_t = Y_t.to(device = 'cuda')\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    predictions = torch.max(ys, 1)[1]\n",
    "    correct_prediction = torch.eq(predictions, ts)\n",
    "    return torch.mean(correct_prediction.float())\n",
    "\n",
    "\n",
    "\n",
    "print(X_t.shape)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "Net = U_Net_Model()\n",
    "Net = torchvision.models.segmentation.deeplabv3_resnet101(num_classes = 9)\n",
    "Net.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    Net.cuda()\n",
    "\n",
    "Net.load_state_dict(model)\n",
    "Net.eval()\n",
    "\n",
    "def nine_to_one(x):\n",
    "    img = np.zeros((256,256))\n",
    "    for i in range(len(x)):\n",
    "        img[:,:] += x[i,:,:]*i\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select_test = np.arange(30)\n",
    "from pytorch_toolbelt.losses import DiceLoss\n",
    "criterion1 = DiceLoss( mode = 'multilabel')\n",
    "count = 0\n",
    "\n",
    "\n",
    "\n",
    "avg_dice = 0\n",
    "for i,x in enumerate(select_test):\n",
    "    test = Net(X_t[x:x+1])['out']\n",
    "    acc = criterion1(test, Y_t[x:x+1])      \n",
    "    acc = acc.item()\n",
    "    #_, test = torch.max(test.data, 1)\n",
    "    test = torch.max(test, 1)[1]\n",
    "    test= test.data.cpu().detach().numpy()\n",
    "    test = np.array(test)[0]\n",
    "    f, axarr = plt.subplots(1,3)\n",
    "    axarr[0].imshow(test)\n",
    "    axarr[0].title.set_text(\"Prediction\")\n",
    "    axarr[0].axis('off')\n",
    "    axarr[1].imshow(test_image_standard_hot_show[x][0])\n",
    "    axarr[1].title.set_text(\"Target\")\n",
    "    axarr[1].axis('off')\n",
    "    axarr[2].imshow(test_image_[x])\n",
    "    axarr[2].title.set_text(\"Original image\")\n",
    "    axarr[2].axis('off')\n",
    "    f.suptitle(\"Dice Score: \" + str(1 - acc)[:4])\n",
    "    f.tight_layout()\n",
    "    f.subplots_adjust(top=1.35)\n",
    "    plt.savefig('/zhome/ed/a/183709/lol/comparison'+str(x) + '.png')\n",
    "    plt.show()\n",
    "    avg_dice += acc/30\n",
    "\n",
    "print(avg_dice)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

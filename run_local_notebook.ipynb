{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUJgrHkXqp2-"
      },
      "source": [
        "## FINAL PROJECT - 02456 DEEP LEARNING\n",
        "### SEGMENTATION OF CAR PARTS\n",
        "### COLLABORATION WITH DELOITTE CONSULTING\n",
        "\n",
        "#### Authors\n",
        ">*Sanem Leblebici - s222448*\n",
        "\n",
        ">*Michal Lehwark - s222999*\n",
        "\n",
        ">*Ari Menachem - s163956*\n",
        "\n",
        ">*Elli Georgiou - s223408*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnTZtRcOzsR8"
      },
      "source": [
        "## DOWNLOAD EXAMPLE DATA AND DEPENDENCIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_zT3stpb6bO"
      },
      "source": [
        "#### PLEASE INSTALL GDOWN WITH THE FOLLOWING COMMAND, IF THIS DOES NOT WORK FOR YOU, YOU CAN DOWNLOAD THE DEPENDENCIES FROM THE LINK BELOW\n",
        "\n",
        "`pip install gdown`\n",
        "\n",
        "https://drive.google.com/drive/folders/1eWNuqKkCmW3Mw7gO4jtSoRVqptaeCPXO?usp=sharing\n",
        "\n",
        "\n",
        "or from dropbox \n",
        "\n",
        "\n",
        "https://www.dropbox.com/scl/fi/y5u1a29r8lb87p1q6k6cl/deep_learning_notebook_files.zip?rlkey=ydofzqhxmkgruejptlji1dy4o&dl=0\n",
        "\n",
        "In case of permission issues contact me directly s222448@dtu.dk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH5Cis1pzrqm"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def download_and_extract_dropbox_zipped_folder(dropbox_zip_url, destination_folder=None):\n",
        "    \"\"\"\n",
        "    Download a zipped folder from Dropbox using gdown, save it, and extract its contents to the specified folder.\n",
        "\n",
        "    Parameters:\n",
        "    - dropbox_zip_url (str): Direct link to the zipped folder in Dropbox.\n",
        "    - destination_folder (str): Folder where the contents of the ZIP file will be extracted. If None or an empty string, the current working directory is used.\n",
        "    \"\"\"\n",
        "    # Set the destination directory as provided or the current working directory\n",
        "    destination_folder = destination_folder or os.getcwd()\n",
        "\n",
        "    # Extract the original filename from the URL\n",
        "    destination_filename = dropbox_zip_url.split('?')[0].split('/')[-1]\n",
        "\n",
        "    # Construct the full destination path for the ZIP file\n",
        "    destination_zip_path = os.path.join(destination_folder, destination_filename)\n",
        "\n",
        "    # Create destination directory if it doesn't exist\n",
        "    os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "    # Download the ZIP file\n",
        "    gdown.download(dropbox_zip_url, destination_zip_path, quiet=False)\n",
        "\n",
        "    # Extract the contents of the ZIP file\n",
        "    with zipfile.ZipFile(destination_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(destination_folder)\n",
        "\n",
        "    # Remove the downloaded ZIP file (optional)\n",
        "    os.remove(destination_zip_path)\n",
        "    \n",
        "# Example usage:\n",
        "dropbox_file_url = \"https://www.dropbox.com/scl/fi/y5u1a29r8lb87p1q6k6cl/deep_learning_notebook_files.zip?rlkey=ydofzqhxmkgruejptlji1dy4o&dl=1\"\n",
        "\n",
        "download_and_extract_dropbox_zipped_folder(dropbox_file_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBJUyJlEsKQ-"
      },
      "source": [
        "## IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8L2MpU8NpnwS"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "from typing import Tuple\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms as T\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from deep_learning_notebook_files.run_results_colab_modules import UNET, UNET_RESNET, DATA_PATH, NUM_EPOCHS, BATCH_SIZE, SPLIT_RATIO, LEARNING_RATE, device, get_data_loaders, pixel_accuracy, save_metric_to_file, num_classes, dice_loss, mean_pixel_accuracy, save_dice_loss_to_file\n",
        "\n",
        "reduced_data_path = \"./deep_learning_notebook_files/reduced_data\"\n",
        "path = \"./deep_learning_notebook_files\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhrxN38krg1t"
      },
      "source": [
        "## TRAINING FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SXmSWEynqyDc"
      },
      "outputs": [],
      "source": [
        "def train(true_if_unet_resnet = False, data_dir = \"arrays\", data_path_colab = reduced_data_path, saveIntermediateModels = False):\n",
        "    print(device)\n",
        "    if true_if_unet_resnet:\n",
        "        model = UNET_RESNET(in_channels=3, out_channels=10)\n",
        "    else:\n",
        "        model = UNET(in_channels=3, out_channels=10)\n",
        "\n",
        "    model.to(device)\n",
        "    print(summary(model, (3, 256, 256)) )\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.to(device)\n",
        "\n",
        "    train_dl, val_dl = get_data_loaders(data_dir, data_path_colab, BATCH_SIZE, SPLIT_RATIO)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), LEARNING_RATE, weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    train_epoch_losses = []\n",
        "    val_epoch_losses = []\n",
        "\n",
        "    if true_if_unet_resnet:\n",
        "        output_models_dir = \"output_models_unet_resnet\"\n",
        "    else:\n",
        "        output_models_dir = \"output_models_unet\"\n",
        "    os.makedirs(output_models_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for images, masks in tqdm(train_dl, desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS}\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss += dice_loss(torch.nn.functional.softmax(outputs, dim=1).float(),\n",
        "                              torch.nn.functional.one_hot(masks, num_classes).permute(0, 3, 1, 2).float(),\n",
        "                              multiclass=True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        average_loss = running_loss / len(train_dl)\n",
        "        train_epoch_losses.append(average_loss)\n",
        "        writer.add_scalar(\"Loss/train\", average_loss, epoch)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in tqdm(val_dl, desc=f\"Validation {epoch + 1}/{NUM_EPOCHS}\"):\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "                loss += dice_loss(torch.nn.functional.softmax(outputs, dim=1).float(),\n",
        "                              torch.nn.functional.one_hot(masks, num_classes).permute(0, 3, 1, 2).float(),\n",
        "                              multiclass=True)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        average_val_loss = val_loss / len(val_dl)\n",
        "        val_epoch_losses.append(average_val_loss)\n",
        "        writer.add_scalar(\"Loss/validation\", average_val_loss, epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {average_loss:.4f}, Val Loss: {average_val_loss:.4f}\")\n",
        "\n",
        "        if saveIntermediateModels:\n",
        "            # Save the trained model every 10 epochs after the 50th epoch\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                model_save_path = os.path.join(\"experiment_outputs\", output_models_dir, f\"unet_model_epoch_{epoch + 1}.pth\")\n",
        "                os.makedirs(os.path.join(\"experiment_outputs\", output_models_dir), exist_ok=True)\n",
        "                torch.save(model.state_dict(), model_save_path)\n",
        "                print(f\"Model saved at epoch {epoch + 1} to {model_save_path}\")\n",
        "\n",
        "    if not saveIntermediateModels:\n",
        "        # Save the trained model at the end\n",
        "        os.makedirs(os.path.join(\"experiment_outputs\", output_models_dir), exist_ok=True)\n",
        "        torch.save(model.state_dict(), os.path.join(\"experiment_outputs\", output_models_dir, f\"unet_model_epoch_{epoch + 1}.pth\"))\n",
        "\n",
        "    # Save the loss data\n",
        "    data = np.column_stack((np.arange(len(train_epoch_losses)), train_epoch_losses, val_epoch_losses))\n",
        "    path = os.path.join(\"experiment_outputs\", output_models_dir, \"loss_data.txt\")\n",
        "    os.makedirs(os.path.join(\"experiment_outputs\", output_models_dir), exist_ok=True)\n",
        "    np.savetxt(path, data, header=\"Index Train_Loss Val_Loss\", comments=\"\", fmt=\"%d %.4f %.4f\")\n",
        "    return path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h4F2r04sMZX"
      },
      "source": [
        "## START A TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ldHkG8isN-J"
      },
      "outputs": [],
      "source": [
        "train(true_if_unet_resnet = False, data_dir = \"arrays\", data_path_colab = reduced_data_path, saveIntermediateModels = False)\n",
        "# Set true_if_unet_resnet True if you will train with resnet enabled UNET, set it to False for original UNET\n",
        "# Set data_path_colab to the path where folders with data arrays are\n",
        "# Set data_dir to the name of the folder under the reduced_data_path including the numpy arrays\n",
        "# Set saveIntermediateModels to True if you want to save every 10 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Kz6wZSsO3S"
      },
      "source": [
        "## LOAD A MODEL WE TRAINED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWUyKXbgsRAM"
      },
      "outputs": [],
      "source": [
        "mdl = UNET()\n",
        "\n",
        "## If you trained a Resnet model, initialize with that model like commented line below\n",
        "# mdl = UNET_RESNET(3)\n",
        "\n",
        "model_name = \"unet_model.pth\"\n",
        "model_type = str(type(mdl))\n",
        "\n",
        "## Can uncomment the next line if your device has gpu\n",
        "# mdl.load_state_dict(torch.load(path + \"/\" + model_name, map_location=torch.device('cuda')))\n",
        "\n",
        "## Can uncomment the next line if your device does not have gpu\n",
        "mdl.load_state_dict(torch.load(path + \"/\" + model_name, map_location=torch.device('cpu')))\n",
        "\n",
        "print(f\"{model_type} loaded: {model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCBUWEEJsZ3r"
      },
      "source": [
        "## TEST LOOP TO GET PREDICTIONS FOR 30 TEST IMAGES SELECTED BY DELOITTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az7eta9esdav"
      },
      "outputs": [],
      "source": [
        "test_set_path = reduced_data_path + '/test_arrays'\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "# Create a list to store the model outputs\n",
        "model_outputs = []\n",
        "model_outputs_images = []\n",
        "model_outputs_gt = []\n",
        "model_output_pixelAcc = []\n",
        "filenames_in_order = []\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "mdl.eval()\n",
        "\n",
        "# Define the transformation to be applied to the input images\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "reverse_transform = transforms.Compose([transforms.ToPILImage()])\n",
        "how_many_images_to_test = 30\n",
        "index = 0\n",
        "\n",
        "for filename in os.listdir(test_set_path):\n",
        "  mask_path = os.path.join(test_set_path, filename)\n",
        "  mask = np.load(mask_path, allow_pickle=True)\n",
        "\n",
        "\n",
        "  img = mask[:, :, :3]\n",
        "  mask_split = mask[:, :, 3]\n",
        "  mask_split = mask_split.astype(int)\n",
        "  one_hot_encoded = np.eye(10, dtype=int)[mask_split.squeeze()]\n",
        "  dice_mask = np.expand_dims(one_hot_encoded.transpose(2,0,1), axis=0)\n",
        "\n",
        "  img = transform(img)\n",
        "  img_rev = reverse_transform(img)\n",
        "\n",
        "  mdl.eval()\n",
        " # Make the prediction\n",
        "  with torch.no_grad():\n",
        "    img = img.unsqueeze(0)\n",
        "    print(\"Predicting for Image \" + str(index+1))\n",
        "    filenames_in_order.append(filename)\n",
        "    output = mdl(img)\n",
        "    argmax_output = torch.argmax(output, dim=1)\n",
        "\n",
        "    # Calculate pixel accuracy\n",
        "    accuracy = pixel_accuracy(argmax_output[0], torch.tensor(mask_split))\n",
        "    model_output_pixelAcc.append(accuracy)\n",
        "\n",
        "  # Store the output in the list\n",
        "  model_outputs.append(argmax_output[0])\n",
        "  model_outputs_images.append(img_rev)\n",
        "  model_outputs_gt.append(torch.tensor(mask_split))\n",
        "\n",
        "  #detect for first 10 images\n",
        "  if index == how_many_images_to_test:\n",
        "    break\n",
        "  index = index + 1\n",
        "\n",
        "# The `model_outputs` list now contains the model's output for each test image\n",
        "# Calculate and print mean pixel accuracy\n",
        "mean_accuracy = mean_pixel_accuracy(model_outputs, model_outputs_gt)\n",
        "\n",
        "# Save scores to a file\n",
        "mean_dice = save_dice_loss_to_file(\"./dice_scores.txt\", model_outputs, model_outputs_gt, filenames_in_order)\n",
        "print(\"Dice Scores Per Each Prediction Saved to File \" + \"dice_scores.txt\")\n",
        "save_metric_to_file(\"./scores.txt\", model_type, model_name, mean_accuracy, mean_dice)\n",
        "print(\"Mean Dice and Pixel Accuracy Scores Saved to File \" + \"scores.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts65S7hgsh7U"
      },
      "source": [
        "## PLOTTING LOSS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcoWBeZ7sjpV"
      },
      "outputs": [],
      "source": [
        "def plot_loss_from_txt(file_path):\n",
        "    # Read data from the text file\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Extract data from each line\n",
        "    indices, train_losses, val_losses = [], [], []\n",
        "    for line in lines[1:]:  # Assuming the first line contains column headers\n",
        "        index, train_loss, val_loss = map(float, line.strip().split())\n",
        "        indices.append(index)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Plot the training and validation losses\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot Training Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(indices, train_losses, label='Train Loss', marker='o', linestyle='-')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Validation Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(indices, val_losses, label='Validation Loss', marker='o', linestyle='-')\n",
        "    plt.title('Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_loss_from_txt(path + '/loss_data.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeK2sBS-smAz"
      },
      "source": [
        "## PLOTTING PREDICTED SEGMENTATION MASKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUD7WYgUspE7"
      },
      "outputs": [],
      "source": [
        "# Define color mapping for each class\n",
        "color_mapping = {\n",
        "        0: (0,0,0),\n",
        "        1: (250, 149, 10),\n",
        "        2: (19, 98, 19),\n",
        "        3: (249, 249, 10),\n",
        "        4: (10, 248, 250),\n",
        "        5: (149, 7, 149),\n",
        "        6: (5, 249, 9),\n",
        "        7: (20, 19, 249),\n",
        "        8: (249, 9, 250),\n",
        "        9: (150, 150, 150),\n",
        "    }\n",
        "\n",
        "def colorize_segmentation_mask(segmentation_tensor_or_mask, mask = False):\n",
        "    # Convert the PyTorch tensor to a NumPy array\n",
        "    if mask == False:\n",
        "        segmentation_array = segmentation_tensor_or_mask.squeeze(0).cpu().numpy()\n",
        "\n",
        "    else:\n",
        "        segmentation_array = segmentation_tensor_or_mask\n",
        "\n",
        "    # Create a mapping from actual class values to color values\n",
        "    class_to_color = {class_value: color_mapping[class_value] for class_value in np.unique(segmentation_array)}\n",
        "\n",
        "    # Create an RGB image with the colored segmentation mask\n",
        "    colored_mask = np.zeros((256, 256, 3), dtype=np.uint8)\n",
        "    for class_value, color in class_to_color.items():\n",
        "        colored_mask[segmentation_array == class_value] = color\n",
        "\n",
        "    return colored_mask\n",
        "\n",
        "for image_index_to_display in range(10):\n",
        "    print(filenames_in_order[image_index_to_display])\n",
        "    segmentation_tensor = model_outputs[image_index_to_display]\n",
        "    mask_tensor = model_outputs_gt[image_index_to_display]\n",
        "\n",
        "    pixel_acc_val = model_output_pixelAcc[image_index_to_display]\n",
        "    image_tensor = model_outputs_images[image_index_to_display]\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(colorize_segmentation_mask(mask_tensor, True))\n",
        "    plt.title('Ground Truth Mask')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(image_tensor)\n",
        "    plt.title('Real Image')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(colorize_segmentation_mask(segmentation_tensor))\n",
        "    plt.title(f\"Pred Mask, pxAcc: {pixel_acc_val:.5f}\")\n",
        "\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

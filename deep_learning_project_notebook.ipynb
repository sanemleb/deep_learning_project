{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## FINAL PROJECT - 02456 DEEP LEARNING\n",
        "### SEGMENTATION OF CAR PARTS\n",
        "### COLLABORATION WITH DELOITTE CONSULTING\n",
        "\n",
        "#### Authors\n",
        ">*Sanem Leblebici - s222448*\n",
        "\n",
        ">*Michal Lehwark - s222999*\n",
        "\n",
        ">*Ari Menachem - s163956*\n",
        "\n",
        ">*Elli Georgiou - s223408*\n"
      ],
      "metadata": {
        "id": "CUJgrHkXqp2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOUNT EXAMPLE DATA"
      ],
      "metadata": {
        "id": "WnTZtRcOzsR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PLEASE PLACE THE FOLLOWING FOLDER IN YOUR GOOGLE DRIVE AND ADJUST THE PATHS BELOW ACCORDINGLY\n",
        "\n",
        "https://drive.google.com/drive/folders/1eWNuqKkCmW3Mw7gO4jtSoRVqptaeCPXO?usp=sharing"
      ],
      "metadata": {
        "id": "U_zT3stpb6bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# MOVE THE REDUCED DATA FOLDER FROM GITHUB TO YOUR DRIVE\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = './drive/MyDrive/deep_learning_notebook_files'\n",
        "reduced_data_path = path + \"/reduced_data\"\n",
        "\n",
        "from drive.MyDrive.deep_learning_notebook_files.run_results_colab_modules import UNET, UNET_RESNET, DATA_PATH, NUM_EPOCHS, BATCH_SIZE, SPLIT_RATIO, LEARNING_RATE, device, get_data_loaders, pixel_accuracy, save_metric_to_file, num_classes, dice_loss, mean_pixel_accuracy, save_dice_loss_to_file\n"
      ],
      "metadata": {
        "id": "fH5Cis1pzrqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTS"
      ],
      "metadata": {
        "id": "sBJUyJlEsKQ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L2MpU8NpnwS"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "from typing import Tuple\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms as T\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING FUNCTION"
      ],
      "metadata": {
        "id": "rhrxN38krg1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(true_if_unet_resnet = False, data_dir = \"arrays\", data_path_colab = reduced_data_path, saveIntermediateModels = False):\n",
        "    print(device)\n",
        "    if true_if_unet_resnet:\n",
        "        model = UNET_RESNET(in_channels=3, out_channels=10)\n",
        "    else:\n",
        "        model = UNET(in_channels=3, out_channels=10)\n",
        "\n",
        "    model.to(device)\n",
        "    print(summary(model, (3, 256, 256)) )\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.to(device)\n",
        "\n",
        "    train_dl, val_dl = get_data_loaders(data_dir, data_path_colab, BATCH_SIZE, SPLIT_RATIO)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), LEARNING_RATE, weight_decay=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    train_epoch_losses = []\n",
        "    val_epoch_losses = []\n",
        "\n",
        "    if true_if_unet_resnet:\n",
        "        output_models_dir = \"output_models_unet_resnet\"\n",
        "    else:\n",
        "        output_models_dir = \"output_models_unet\"\n",
        "    os.makedirs(output_models_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for images, masks in tqdm(train_dl, desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS}\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            loss += dice_loss(torch.nn.functional.softmax(outputs, dim=1).float(),\n",
        "                              torch.nn.functional.one_hot(masks, num_classes).permute(0, 3, 1, 2).float(),\n",
        "                              multiclass=True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        average_loss = running_loss / len(train_dl)\n",
        "        train_epoch_losses.append(average_loss)\n",
        "        writer.add_scalar(\"Loss/train\", average_loss, epoch)\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in tqdm(val_dl, desc=f\"Validation {epoch + 1}/{NUM_EPOCHS}\"):\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks)\n",
        "                loss += dice_loss(torch.nn.functional.softmax(outputs, dim=1).float(),\n",
        "                              torch.nn.functional.one_hot(masks, num_classes).permute(0, 3, 1, 2).float(),\n",
        "                              multiclass=True)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        average_val_loss = val_loss / len(val_dl)\n",
        "        val_epoch_losses.append(average_val_loss)\n",
        "        writer.add_scalar(\"Loss/validation\", average_val_loss, epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {average_loss:.4f}, Val Loss: {average_val_loss:.4f}\")\n",
        "\n",
        "        if saveIntermediateModels:\n",
        "            # Save the trained model every 10 epochs after the 50th epoch\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                model_save_path = os.path.join(\"experiment_outputs\", output_models_dir, f\"unet_model_epoch_{epoch + 1}.pth\")\n",
        "                os.makedirs(os.path.join(\"experiment_outputs\", output_models_dir), exist_ok=True)\n",
        "                torch.save(model.state_dict(), model_save_path)\n",
        "                print(f\"Model saved at epoch {epoch + 1} to {model_save_path}\")\n",
        "\n",
        "    if not saveIntermediateModels:\n",
        "        # Save the trained model at the end\n",
        "        os.makedirs(os.path.join(\"experiment_outputs\", output_models_dir), exist_ok=True)\n",
        "        torch.save(model.state_dict(), os.path.join(\"experiment_outputs\", output_models_dir, f\"unet_model_epoch_{epoch + 1}.pth\"))\n",
        "\n",
        "    # Save the loss data\n",
        "    data = np.column_stack((np.arange(len(train_epoch_losses)), train_epoch_losses, val_epoch_losses))\n",
        "    path = os.path.join(\"experiment_outputs\", output_models_dir, \"loss_data.txt\")\n",
        "    os.makedirs(os.path.join(\"experiment_outputs\", output_models_dir), exist_ok=True)\n",
        "    np.savetxt(path, data, header=\"Index Train_Loss Val_Loss\", comments=\"\", fmt=\"%d %.4f %.4f\")\n",
        "    return path"
      ],
      "metadata": {
        "id": "SXmSWEynqyDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## START A TRAINING"
      ],
      "metadata": {
        "id": "4h4F2r04sMZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(true_if_unet_resnet = False, data_dir = \"arrays\", data_path_colab = reduced_data_path, saveIntermediateModels = False)\n",
        "# Set true_if_unet_resnet True if you will train with resnet enabled UNET, set it to False for original UNET\n",
        "# Set data_path_colab to the path where folders with data arrays are\n",
        "# Set data_dir to the name of the folder under the reduced_data_path including the numpy arrays\n",
        "# Set saveIntermediateModels to True if you want to save every 10 epochs"
      ],
      "metadata": {
        "id": "4ldHkG8isN-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOAD A MODEL WE TRAINED"
      ],
      "metadata": {
        "id": "3_Kz6wZSsO3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mdl = UNET()\n",
        "\n",
        "## If you trained a Resnet model, initialize with that model like commented line below\n",
        "# mdl = UNET_RESNET(3)\n",
        "\n",
        "model_name = \"unet_model.pth\"\n",
        "model_type = str(type(mdl))\n",
        "\n",
        "mdl.load_state_dict(torch.load(path + \"/\" + model_name, map_location=torch.device('cuda')))\n",
        "\n",
        "## Can uncomment the next line if your device does not have gpu\n",
        "# mdl.load_state_dict(torch.load(path + \"/\" + model_name, map_location=torch.device('cpu')))\n",
        "\n",
        "print(f\"{model_type} loaded: {model_name}\")"
      ],
      "metadata": {
        "id": "FWUyKXbgsRAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST LOOP TO GET PREDICTIONS FOR 30 TEST IMAGES SELECTED BY DELOITTE"
      ],
      "metadata": {
        "id": "vCBUWEEJsZ3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_path = reduced_data_path + '/test_arrays'\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "# Create a list to store the model outputs\n",
        "model_outputs = []\n",
        "model_outputs_images = []\n",
        "model_outputs_gt = []\n",
        "model_output_pixelAcc = []\n",
        "filenames_in_order = []\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "mdl.eval()\n",
        "\n",
        "# Define the transformation to be applied to the input images\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "reverse_transform = transforms.Compose([transforms.ToPILImage()])\n",
        "how_many_images_to_test = 30\n",
        "index = 0\n",
        "\n",
        "for filename in os.listdir(test_set_path):\n",
        "  mask_path = os.path.join(test_set_path, filename)\n",
        "  mask = np.load(mask_path, allow_pickle=True)\n",
        "\n",
        "\n",
        "  img = mask[:, :, :3]\n",
        "  mask_split = mask[:, :, 3]\n",
        "  mask_split = mask_split.astype(int)\n",
        "  one_hot_encoded = np.eye(10, dtype=int)[mask_split.squeeze()]\n",
        "  dice_mask = np.expand_dims(one_hot_encoded.transpose(2,0,1), axis=0)\n",
        "\n",
        "  img = transform(img)\n",
        "  img_rev = reverse_transform(img)\n",
        "\n",
        "  mdl.eval()\n",
        " # Make the prediction\n",
        "  with torch.no_grad():\n",
        "    img = img.unsqueeze(0)\n",
        "    print(\"Predicting for Image \" + str(index+1))\n",
        "    filenames_in_order.append(filename)\n",
        "    output = mdl(img)\n",
        "    argmax_output = torch.argmax(output, dim=1)\n",
        "\n",
        "    # Calculate pixel accuracy\n",
        "    accuracy = pixel_accuracy(argmax_output[0], torch.tensor(mask_split))\n",
        "    model_output_pixelAcc.append(accuracy)\n",
        "\n",
        "  # Store the output in the list\n",
        "  model_outputs.append(argmax_output[0])\n",
        "  model_outputs_images.append(img_rev)\n",
        "  model_outputs_gt.append(torch.tensor(mask_split))\n",
        "\n",
        "  #detect for first 10 images\n",
        "  if index == how_many_images_to_test:\n",
        "    break\n",
        "  index = index + 1\n",
        "\n",
        "# The `model_outputs` list now contains the model's output for each test image\n",
        "# Calculate and print mean pixel accuracy\n",
        "mean_accuracy = mean_pixel_accuracy(model_outputs, model_outputs_gt)\n",
        "\n",
        "# Save scores to a file\n",
        "mean_dice = save_dice_loss_to_file(\"./dice_scores.txt\", model_outputs, model_outputs_gt, filenames_in_order)\n",
        "print(\"Dice Scores Per Each Prediction Saved to File \" + \"dice_scores.txt\")\n",
        "save_metric_to_file(\"./scores.txt\", model_type, model_name, mean_accuracy, mean_dice)\n",
        "print(\"Mean Dice and Pixel Accuracy Scores Saved to File \" + \"scores.txt\")"
      ],
      "metadata": {
        "id": "Az7eta9esdav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PLOTTING LOSS"
      ],
      "metadata": {
        "id": "ts65S7hgsh7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_from_txt(file_path):\n",
        "    # Read data from the text file\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Extract data from each line\n",
        "    indices, train_losses, val_losses = [], [], []\n",
        "    for line in lines[1:]:  # Assuming the first line contains column headers\n",
        "        index, train_loss, val_loss = map(float, line.strip().split())\n",
        "        indices.append(index)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Plot the training and validation losses\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot Training Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(indices, train_losses, label='Train Loss', marker='o', linestyle='-')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Validation Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(indices, val_losses, label='Validation Loss', marker='o', linestyle='-')\n",
        "    plt.title('Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Show the plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_loss_from_txt(path + '/loss_data.txt')"
      ],
      "metadata": {
        "id": "JcoWBeZ7sjpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PLOTTING PREDICTED SEGMENTATION MASKS"
      ],
      "metadata": {
        "id": "FeK2sBS-smAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define color mapping for each class\n",
        "color_mapping = {\n",
        "        0: (0,0,0),\n",
        "        1: (250, 149, 10),\n",
        "        2: (19, 98, 19),\n",
        "        3: (249, 249, 10),\n",
        "        4: (10, 248, 250),\n",
        "        5: (149, 7, 149),\n",
        "        6: (5, 249, 9),\n",
        "        7: (20, 19, 249),\n",
        "        8: (249, 9, 250),\n",
        "        9: (150, 150, 150),\n",
        "    }\n",
        "\n",
        "def colorize_segmentation_mask(segmentation_tensor_or_mask, mask = False):\n",
        "    # Convert the PyTorch tensor to a NumPy array\n",
        "    if mask == False:\n",
        "        segmentation_array = segmentation_tensor_or_mask.squeeze(0).cpu().numpy()\n",
        "\n",
        "    else:\n",
        "        segmentation_array = segmentation_tensor_or_mask\n",
        "\n",
        "    # Create a mapping from actual class values to color values\n",
        "    class_to_color = {class_value: color_mapping[class_value] for class_value in np.unique(segmentation_array)}\n",
        "\n",
        "    # Create an RGB image with the colored segmentation mask\n",
        "    colored_mask = np.zeros((256, 256, 3), dtype=np.uint8)\n",
        "    for class_value, color in class_to_color.items():\n",
        "        colored_mask[segmentation_array == class_value] = color\n",
        "\n",
        "    return colored_mask\n",
        "\n",
        "for image_index_to_display in range(10):\n",
        "    print(filenames_in_order[image_index_to_display])\n",
        "    segmentation_tensor = model_outputs[image_index_to_display]\n",
        "    mask_tensor = model_outputs_gt[image_index_to_display]\n",
        "\n",
        "    pixel_acc_val = model_output_pixelAcc[image_index_to_display]\n",
        "    image_tensor = model_outputs_images[image_index_to_display]\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(colorize_segmentation_mask(mask_tensor, True))\n",
        "    plt.title('Ground Truth Mask')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(image_tensor)\n",
        "    plt.title('Real Image')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(colorize_segmentation_mask(segmentation_tensor))\n",
        "    plt.title(f\"Pred Mask, pxAcc: {pixel_acc_val:.5f}\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hUD7WYgUspE7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}